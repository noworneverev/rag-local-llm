{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source from: https://colab.research.google.com/drive/1OZpmLgd5D_qmjTnL5AsD1_ZJDdb7LQZI?usp=sharing#scrollTo=KH546j3nkFwX\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import GPT2TokenizerFast\n",
    "from transformers import AutoTokenizer\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "model_path = './models/llama-2-7b-chat.Q4_K_M.gguf'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Loading PDFs and chunking with LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "page_content='Attention Is All You Need\\nAshish Vaswani∗\\nGoogle Brain\\navaswani@google.comNoam Shazeer∗\\nGoogle Brain\\nnoam@google.comNiki Parmar∗\\nGoogle Research\\nnikip@google.comJakob Uszkoreit∗\\nGoogle Research\\nusz@google.com\\nLlion Jones∗\\nGoogle Research\\nllion@google.comAidan N. Gomez∗†\\nUniversity of Toronto\\naidan@cs.toronto.eduŁukasz Kaiser∗\\nGoogle Brain\\nlukaszkaiser@google.com\\nIllia Polosukhin∗‡\\nillia.polosukhin@gmail.com\\nAbstract\\nThe dominant sequence transduction models are based on complex recurrent or\\nconvolutional neural networks that include an encoder and a decoder. The best\\nperforming models also connect the encoder and decoder through an attention\\nmechanism. We propose a new simple network architecture, the Transformer,\\nbased solely on attention mechanisms, dispensing with recurrence and convolutions\\nentirely. Experiments on two machine translation tasks show these models to\\nbe superior in quality while being more parallelizable and requiring signiﬁcantly\\nless time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-\\nto-German translation task, improving over the existing best results, including\\nensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task,\\nour model establishes a new single-model state-of-the-art BLEU score of 41.0 after\\ntraining for 3.5 days on eight GPUs, a small fraction of the training costs of the\\nbest models from the literature.\\n1 Introduction\\nRecurrent neural networks, long short-term memory [ 12] and gated recurrent [ 7] neural networks\\nin particular, have been ﬁrmly established as state of the art approaches in sequence modeling and\\ntransduction problems such as language modeling and machine translation [ 29,2,5]. Numerous\\nefforts have since continued to push the boundaries of recurrent language models and encoder-decoder\\narchitectures [31, 21, 13].\\n∗Equal contribution. Listing order is random. Jakob proposed replacing RNNs with self-attention and started\\nthe effort to evaluate this idea. Ashish, with Illia, designed and implemented the ﬁrst Transformer models and\\nhas been crucially involved in every aspect of this work. Noam proposed scaled dot-product attention, multi-head\\nattention and the parameter-free position representation and became the other person involved in nearly every\\ndetail. Niki designed, implemented, tuned and evaluated countless model variants in our original codebase and\\ntensor2tensor. Llion also experimented with novel model variants, was responsible for our initial codebase, and\\nefﬁcient inference and visualizations. Lukasz and Aidan spent countless long days designing various parts of and\\nimplementing tensor2tensor, replacing our earlier codebase, greatly improving results and massively accelerating\\nour research.\\n†Work performed while at Google Brain.\\n‡Work performed while at Google Research.\\n31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA.' metadata={'source': './docs/attention-is-all-you-need-Paper.pdf', 'page': 0}\n"
     ]
    }
   ],
   "source": [
    "# Simple method - Split by pages \n",
    "loader = PyPDFLoader(\"./docs/attention-is-all-you-need-Paper.pdf\")\n",
    "pages = loader.load_and_split()\n",
    "print(len(pages))\n",
    "print(pages[0])\n",
    "\n",
    "# SKIP TO STEP 2 IF YOU'RE USING THIS METHOD\n",
    "chunks = pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "vocab.json: 100%|██████████| 1.04M/1.04M [00:00<00:00, 3.50MB/s]\n",
      "c:\\Hiwi_Project\\langchain-local-model\\venv\\lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\n9102\\.cache\\huggingface\\hub\\models--gpt2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 6.13MB/s]\n",
      "tokenizer.json: 100%|██████████| 1.36M/1.36M [00:00<00:00, 10.9MB/s]\n",
      "config.json: 100%|██████████| 665/665 [00:00<?, ?B/s] \n"
     ]
    }
   ],
   "source": [
    "# Advanced method - Split by chunk\n",
    "\n",
    "# Step 1: Convert PDF to text\n",
    "import textract\n",
    "doc = textract.process(r\"./docs/attention-is-all-you-need-Paper.pdf\")\n",
    "\n",
    "# Step 2: Save to .txt and reopen (helps prevent issues)\n",
    "with open('./docs/attention-is-all-you-need-Paper.txt', 'w', encoding=\"utf-8\") as f:\n",
    "    f.write(doc.decode('utf-8'))\n",
    "\n",
    "with open('./docs/attention-is-all-you-need-Paper.txt', 'r', encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "# Step 3: Create function to count tokens\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"NousResearch/Llama-2-7b-chat-hf\")\n",
    "\n",
    "def count_tokens(text: str) -> int:\n",
    "    return len(tokenizer.encode(text))\n",
    "\n",
    "# Step 4: Split text into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    # Set a really small chunk size, just to show.\n",
    "    chunk_size = 512,\n",
    "    chunk_overlap  = 24,\n",
    "    length_function = count_tokens,\n",
    ")\n",
    "\n",
    "chunks = text_splitter.create_documents([text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.documents.base.Document"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(chunks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Quick data visualization to ensure chunking was successful\n",
    "\n",
    "# Create a list of token counts\n",
    "token_counts = [count_tokens(chunk.page_content) for chunk in chunks]\n",
    "\n",
    "# Create a DataFrame from the token counts\n",
    "df = pd.DataFrame({'Token Count': token_counts})\n",
    "\n",
    "# Create a histogram of the token count distribution\n",
    "df.hist(bins=40, )\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Embed text and store embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import GPT4AllEmbeddings\n",
    "from langchain_community.embeddings import LlamaCppEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "# Get embedding model\n",
    "# embeddings = OpenAIEmbeddings()\n",
    "embeddings = GPT4AllEmbeddings()\n",
    "# embeddings = LlamaCppEmbeddings(model_path=model_path)\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=chunks, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Set up local LLM using LlamaCpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 0 | VSX = 0 | \n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms import LlamaCpp\n",
    "\n",
    "n_gpu_layers = 1  # Metal set to 1 is enough.\n",
    "n_batch = 512  # Should be between 1 and n_ctx, consider the amount of RAM of your Apple Silicon Chip.\n",
    "\n",
    "llm = LlamaCpp(\n",
    "    model_path=model_path,        \n",
    "    n_gpu_layers=n_gpu_layers,\n",
    "    n_batch=n_batch,\n",
    "    n_ctx=2048,\n",
    "    f16_kv=True,  # MUST set to True, otherwise you will run into problem after a couple of calls\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Setup retrieval function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='To the best of our knowledge, however, the Transformer is the first transduction model relying entirely on self-attention to compute representations of its input and output without using sequencealigned RNNs or convolution. In the following sections, we will describe the Transformer, motivate self-attention and discuss its advantages over models such as [14, 15] and [8].\\n\\n3 Model Architecture\\n\\nMost competitive neural sequence transduction models have an encoder-decoder structure [5, 2, 29]. Here, the encoder maps an input sequence of symbol representations (x1, ..., xn) to a sequence of continuous representations z = (z1, ..., zn). Given z, the decoder then generates an output sequence (y1, ..., ym) of symbols one element at a time. At each step the model is auto-regressive [9], consuming the previously generated symbols as additional input when generating the next.\\n\\nThe Transformer follows this overall architecture using stacked self-attention and point-wise, fully connected layers for both the encoder and decoder, shown in the left and right halves of Figure 1, respectively.\\n\\n3.1 Encoder and Decoder Stacks\\n\\nEncoder: The encoder is composed of a stack of N = 6 identical layers. Each layer has two sub-layers. The first is a multi-head self-attention mechanism, and the second is a simple, position-\\n\\n2\\n\\n\\n\\n\\x0cFigure 1: The Transformer - model architecture.\\n\\nwise fully connected feed-forward network. We employ a residual connection [10] around each of the two sub-layers, followed by layer normalization [1]. That is, the output of each sub-layer is LayerNorm(x + Sublayer(x)), where Sublayer(x) is the function implemented by the sub-layer itself. To facilitate these residual connections, all sub-layers in the model, as well as the embedding layers, produce outputs of dimension dmodel = 512.')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check similarity search is working\n",
    "query = \"Who created transformers?\"\n",
    "docs = vectorstore.similarity_search(query)\n",
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Jakob Uszkoreit, Ashish Vaswani et al.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create QA chain to integrate similarity search with user queries (answer query from knowledge base)\n",
    "\n",
    "chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
    "\n",
    "query = \"Who created transformers?\"\n",
    "docs = vectorstore.similarity_search(query)\n",
    "\n",
    "chain.run(input_documents=docs, question=query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Create chatbot with chat memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# Create conversation chain that uses our vectordb as retriver, this also allows for chat history management\n",
    "qa = ConversationalRetrievalChain.from_llm(llm, vectorstore.as_retriever())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the Transformers chatbot! Type 'exit' to stop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\n9102\\AppData\\Local\\Temp\\ipykernel_2588\\3970211031.py:20: DeprecationWarning: on_submit is deprecated. Instead, set the .continuous_update attribute to False and observe the value changing with: mywidget.observe(callback, 'value').\n",
      "  input_box.on_submit(on_submit)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d5e3a8da1a24d31afd4ae53e65370e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', placeholder='Please enter your question:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4f8d52b20f548b99c4b14ce3978d702",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<b>User:</b> Who created transformers?')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "febcda6b7eb642a2a9a124c3e2019b15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<b><font color=\"blue\">Chatbot:</font></b>  The Transformer was proposed by several authors, includ…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d0c406c338949ea99b11df007ad4f89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<b>User:</b> Were they smart?')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c3852af48eb4e57a5ac752511ef5f5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<b><font color=\"blue\">Chatbot:</font></b>   The authors proposed the Transformer using a stacked s…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00b35c368b9d44ada2b8f07fb91d63b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<b>User:</b>  I think they were')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15221c220a0848e2a2d0eb4b29cc65f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<b><font color=\"blue\">Chatbot:</font></b>   I can provide information on the authors who proposed …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chat_history = []\n",
    "\n",
    "def on_submit(_):\n",
    "    query = input_box.value\n",
    "    input_box.value = \"\"\n",
    "    \n",
    "    if query.lower() == 'exit':\n",
    "        print(\"Thank you for using the State of the Union chatbot!\")\n",
    "        return\n",
    "    \n",
    "    result = qa({\"question\": query, \"chat_history\": chat_history})\n",
    "    chat_history.append((query, result['answer']))\n",
    "    \n",
    "    display(widgets.HTML(f'<b>User:</b> {query}'))\n",
    "    display(widgets.HTML(f'<b><font color=\"blue\">Chatbot:</font></b> {result[\"answer\"]}'))\n",
    "\n",
    "print(\"Welcome to the Transformers chatbot! Type 'exit' to stop.\")\n",
    "\n",
    "input_box = widgets.Text(placeholder='Please enter your question:')\n",
    "input_box.on_submit(on_submit)\n",
    "\n",
    "display(input_box)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
